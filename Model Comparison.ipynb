{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pystan\n",
    "import seaborn as sns\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import stan convergence utilities from local directory \n",
    "Utilities originally by Betancourt, [see this notebook on Bayesian workflow](http://mc-stan.org/users/documentation/case-studies/pystan_workflow.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utility/stan_utility.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    \"\"\"Saves the compiled model to file.\"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "def load_model(filename):\n",
    "    \"\"\"Load already compiled model from file.\"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. Model Comparison__\n",
    "Load all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stanfit4anon_model_292039ab535cf44cf201c28c58f22d90_4516776706501392494'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b847c25767d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                '5 Predictors Informative inter, Normal']\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mM_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-b847c25767d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m                '5 Predictors Informative inter, Normal']\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mM_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-12b49725afba>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"\"\"Load already compiled model from file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stanfit4anon_model_292039ab535cf44cf201c28c58f22d90_4516776706501392494'"
     ]
    }
   ],
   "source": [
    "model_filenames = ['lin_3_uninformative.stan.saved',\n",
    "                   'lin_3_informative.stan.saved',\n",
    "                   'lin_5_informative.stan.saved',\n",
    "                   'lin_5_informative-interaction.stan.saved']\n",
    "\n",
    "model_names = ['3 Predictors Uninformative',\n",
    "               '3 Predictors Informative, Normal',\n",
    "               '5 Predictors Informative, Normal',\n",
    "               '5 Predictors Informative inter, Normal']\n",
    "\n",
    "models = [load_model(M_name) for M_name in model_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate PSIS-LOO-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['α','β_1','β_2','β_3','β_4','β_5','β_6','β_7','sigma']\n",
    "params_mean =  [e + ',μ' for e in params]\n",
    "params_stds =  [e + ',σ' for e in params]\n",
    "df = pd.DataFrame(columns=[params_mean + params_stds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrreflex/anaconda3/envs/bdaproject/lib/python3.7/site-packages/arviz/stats/stats.py:372: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for\n",
      "        one or more samples. You should consider using a more robust model, this is because\n",
      "        importance sampling is less likely to work well if the marginal posterior and LOO posterior\n",
      "        are very different. This is more likely to happen with a non-robust model and highly\n",
      "        influential observations.\n",
      "  influential observations.\"\"\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['α | μ' 'β_1 | μ' 'β_2 | μ' 'β_3 | μ' 'β_4 | μ' 'β_5 | μ' 'β_6 | μ'\\n 'β_7 | μ' 'sigma | μ'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-d05f12ffa0ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdf_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_M\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams_mean\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams_stds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bdaproject/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bdaproject/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bdaproject/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['α | μ' 'β_1 | μ' 'β_2 | μ' 'β_3 | μ' 'β_4 | μ' 'β_5 | μ' 'β_6 | μ'\\n 'β_7 | μ' 'sigma | μ'] not in index\""
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "loos = []\n",
    "params = ['α','β_1','β_2','β_3','β_4','β_5','β_6','β_7','sigma']\n",
    "\n",
    "for M in models:\n",
    "    azfit = az.from_pystan(fit=M, prior=prior_dict, \n",
    "                           observed_data='y', \n",
    "                           posterior_predictive='ypred', \n",
    "                           log_likelihood='log_lik')\n",
    "    df_M = az.loo(azfit)\n",
    "    \n",
    "    m_s = []\n",
    "    for func in [lambda X: np.mean(X), lambda X: np.var(X)]:\n",
    "        m_s.append([func(M['a'])] + [func(M['b'][:,i]) for i in range(M['b'].shape[1])] + [func(M['sigma'])])\n",
    "    \n",
    "    df_M = pd.concat([df_M,df],axis=1)\n",
    "    df_M.loc[params_mean] = m_s[0]\n",
    "    df_M.loc[params_stds] = m_s[1]\n",
    "    loos.append(df_M)\n",
    "\n",
    "loos_merged = reduce(lambda left,right: pd.concat([left,right], axis=0), loos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loo</th>\n",
       "      <th>loo_se</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>warning</th>\n",
       "      <th>(α | μ,)</th>\n",
       "      <th>(β_1 | μ,)</th>\n",
       "      <th>(β_2 | μ,)</th>\n",
       "      <th>(β_3 | μ,)</th>\n",
       "      <th>(β_4 | μ,)</th>\n",
       "      <th>(β_5 | μ,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(sigma | μ,)</th>\n",
       "      <th>(α | σ,)</th>\n",
       "      <th>(β_1 | σ,)</th>\n",
       "      <th>(β_2 | σ,)</th>\n",
       "      <th>(β_3 | σ,)</th>\n",
       "      <th>(β_4 | σ,)</th>\n",
       "      <th>(β_5 | σ,)</th>\n",
       "      <th>(β_6 | σ,)</th>\n",
       "      <th>(β_7 | σ,)</th>\n",
       "      <th>(sigma | σ,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3 Predictors Uninformative</th>\n",
       "      <td>-5096.359694</td>\n",
       "      <td>5532.216878</td>\n",
       "      <td>7362.516070</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 Predictors Informative, Normal</th>\n",
       "      <td>-6133.387852</td>\n",
       "      <td>5467.369648</td>\n",
       "      <td>6585.259986</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 Predictors Informative, Normal</th>\n",
       "      <td>-4655.450268</td>\n",
       "      <td>5840.526255</td>\n",
       "      <td>7195.049404</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 Predictors Informative inter, Normal</th>\n",
       "      <td>-3597.043730</td>\n",
       "      <td>5961.645286</td>\n",
       "      <td>7682.618950</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                loo       loo_se        p_loo  \\\n",
       "3 Predictors Uninformative             -5096.359694  5532.216878  7362.516070   \n",
       "3 Predictors Informative, Normal       -6133.387852  5467.369648  6585.259986   \n",
       "5 Predictors Informative, Normal       -4655.450268  5840.526255  7195.049404   \n",
       "5 Predictors Informative inter, Normal -3597.043730  5961.645286  7682.618950   \n",
       "\n",
       "                                        warning (α | μ,) (β_1 | μ,)  \\\n",
       "3 Predictors Uninformative                    1      NaN        NaN   \n",
       "3 Predictors Informative, Normal              1      NaN        NaN   \n",
       "5 Predictors Informative, Normal              1      NaN        NaN   \n",
       "5 Predictors Informative inter, Normal        1      NaN        NaN   \n",
       "\n",
       "                                       (β_2 | μ,) (β_3 | μ,) (β_4 | μ,)  \\\n",
       "3 Predictors Uninformative                    NaN        NaN        NaN   \n",
       "3 Predictors Informative, Normal              NaN        NaN        NaN   \n",
       "5 Predictors Informative, Normal              NaN        NaN        NaN   \n",
       "5 Predictors Informative inter, Normal        NaN        NaN        NaN   \n",
       "\n",
       "                                       (β_5 | μ,)     ...      (sigma | μ,)  \\\n",
       "3 Predictors Uninformative                    NaN     ...               NaN   \n",
       "3 Predictors Informative, Normal              NaN     ...               NaN   \n",
       "5 Predictors Informative, Normal              NaN     ...               NaN   \n",
       "5 Predictors Informative inter, Normal        NaN     ...               NaN   \n",
       "\n",
       "                                       (α | σ,) (β_1 | σ,) (β_2 | σ,)  \\\n",
       "3 Predictors Uninformative                  NaN        NaN        NaN   \n",
       "3 Predictors Informative, Normal            NaN        NaN        NaN   \n",
       "5 Predictors Informative, Normal            NaN        NaN        NaN   \n",
       "5 Predictors Informative inter, Normal      NaN        NaN        NaN   \n",
       "\n",
       "                                       (β_3 | σ,) (β_4 | σ,) (β_5 | σ,)  \\\n",
       "3 Predictors Uninformative                    NaN        NaN        NaN   \n",
       "3 Predictors Informative, Normal              NaN        NaN        NaN   \n",
       "5 Predictors Informative, Normal              NaN        NaN        NaN   \n",
       "5 Predictors Informative inter, Normal        NaN        NaN        NaN   \n",
       "\n",
       "                                       (β_6 | σ,) (β_7 | σ,) (sigma | σ,)  \n",
       "3 Predictors Uninformative                    NaN        NaN          NaN  \n",
       "3 Predictors Informative, Normal              NaN        NaN          NaN  \n",
       "5 Predictors Informative, Normal              NaN        NaN          NaN  \n",
       "5 Predictors Informative inter, Normal        NaN        NaN          NaN  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loos_merged.set_axis(model_names, axis=0, inplace=True)\n",
    "loos_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use leave-one-out cross validation (LOO-CV) to assess the predictive performance of the different models.\n",
    "\n",
    ">* PSIS-LOO values, the effective number of parameters peff , and the k-values for each of the\n",
    "three models\n",
    "\n",
    ">* an assessment of how reliable the PSIS-LOO estimates are for the three models based on\n",
    "the k-values\n",
    "\n",
    ">* an assessment of whether there are differences between the models, and if so, which model\n",
    "should be selected according to PSIS-LOO\n",
    "\n",
    ">* number of effective parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __4. Conclusions__\n",
    ">  Even the coin tosses and die rolls ubiquitous in probability theory texts are not truly exchangeable. The more relevant question is, ‘Do the model’s deficiencies have a noticeable effect on the substantive inferences?’\n",
    "p 142\n",
    "\n",
    "\n",
    ">More formally, we can check a model by external validation using the model to make predic-\n",
    "tions about future data, and then collecting those data and comparing to their predictions.\n",
    "Posterior means should be correct on average, 50% intervals should contain the true values\n",
    "half the time, and so forth. p. 143\n",
    "\n",
    "See the hierarchical regression model: 142->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "Would the results be easier to interpret if we would normalize the streams to interval [0,1]?\n",
    "\n",
    "We need to conduct proper sensitivity analysis using different priors and try to develop intuition about the data / hypothesize with more clarity. How to formulate reasonable priors for quite arbitrary linear coefficients $\\beta$? Explaining the steepness of slope... \n",
    "\n",
    "Also we should think about how to construct hierarchical priors based on earlier data (weekly top 100). Also develop understanding about the make-up off global data - differing countries with differing cultures. For example chinese or italian music could be quite different compared to UK music. We should also train on Finnish and Swedish data and compare cultural differences by comparing posteriors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
